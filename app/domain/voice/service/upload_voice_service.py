# app/domain/voice/service.py
import os
import tempfile
import uuid

import librosa
from fastapi import UploadFile
from pydub import AudioSegment
from sqlalchemy.orm import Session

from app.domain.user.model.user import User
from app.domain.voice.model.voice import Voice, VoiceSegment
from app.domain.voice.utils.draw_dB_image import draw
from app.domain.llm.service.classify_text_service import classify_text_into_sections
from app.domain.voice.utils.map_sections_to_segments import (
    map_llm_sections_to_whisper_segments,
    map_sentences_to_whisper_segments
)
from app.infrastructure.storage.object_storage import upload_file
from app.utils.audio_analyzer import transcribe_audio, analyze_segment_audio, analyze_segments
from app.utils.feedback_rules import make_feedback


def _remove_duplicate_segments(segments: list) -> list:
    """
    ì¤‘ë³µëœ segmentsë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    ê°™ì€ ì‹œê°„ ë²”ìœ„(start, end)ì™€ í…ìŠ¤íŠ¸ë¥¼ ê°€ì§„ segmentëŠ” í•˜ë‚˜ë§Œ ìœ ì§€í•©ë‹ˆë‹¤.
    part ì •ë³´ëŠ” ì²« ë²ˆì§¸ë¡œ ë‚˜íƒ€ë‚œ ê²ƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        segments: segment ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ì¤‘ë³µì´ ì œê±°ëœ segment ë¦¬ìŠ¤íŠ¸
    """
    seen = {}  # (start, end, text) -> segment
    result = []
    
    for seg in segments:
        # ì‹œê°„ê³¼ í…ìŠ¤íŠ¸ë¡œ ê³ ìœ  í‚¤ ìƒì„±
        key = (
            round(seg.get("start", 0), 3),  # ì†Œìˆ˜ì  3ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼
            round(seg.get("end", 0), 3),
            seg.get("text", "").strip()
        )
        
        if key not in seen:
            seen[key] = seg
            result.append(seg)
        else:
            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°, part ì •ë³´ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸ (ìš°ì„ ìˆœìœ„: ì„œë¡  > ë³¸ë¡  > ê²°ë¡ )
            existing = seen[key]
            existing_part = existing.get("part", "")
            new_part = seg.get("part", "")
            
            # part ìš°ì„ ìˆœìœ„: ì„œë¡  > ë³¸ë¡  > ê²°ë¡ 
            part_priority = {"ì„œë¡ ": 1, "ë³¸ë¡ ": 2, "ê²°ë¡ ": 3}
            existing_priority = part_priority.get(existing_part, 99)
            new_priority = part_priority.get(new_part, 99)
            
            # ìš°ì„ ìˆœìœ„ê°€ ë†’ì€(ìˆ«ìê°€ ì‘ì€) partë¡œ ì—…ë°ì´íŠ¸
            if new_priority < existing_priority:
                existing["part"] = new_part
                print(f"âš ï¸ ì¤‘ë³µ segment ë°œê²¬: '{seg.get('text', '')[:30]}...' - partë¥¼ '{new_part}'ë¡œ ì—…ë°ì´íŠ¸")
    
    return result


def save_segments_to_storage(local_path, voice_id, segments, db, voice, ext):
    audio = AudioSegment.from_file(local_path)
    saved_segments = []
    for order_no, seg in enumerate(segments, start=1):
        seg_audio = audio[int(seg["start"] * 1000):int(seg["end"] * 1000)]
        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=ext)
        ext = ext.replace(".", "")
        format_map = {
            "m4a": "mp4",
            "aac": "adts",
            "wav": "wav",
            "mp3": "mp3"
        }
        fmt = format_map.get(ext, ext)  # ê¸°ë³¸ì€ ê·¸ëŒ€ë¡œ
        seg_audio.export(tmp_file.name, format=fmt)

        object_name = f"voices/{voice_id}/segments/seg_{order_no}"
        seg_url = upload_file(tmp_file.name, object_name)
        met = seg.get("metrics", {})
        words = seg.get("words", [])
        segment = VoiceSegment(
            voice_id=voice.id,
            order_no=order_no,
            text=seg["text"],
            part=seg.get("part"), 
            start_time=float(seg["start"]),
            end_time=float(seg["end"]),
            segment_url=seg_url,
            db=float(met.get("dB", 0.0)),
            pitch_mean_hz=float(met.get("pitch_mean_hz", 0.0)),
            rate_wpm=float(met.get("rate_wpm", 0.0)),
            pause_ratio=float(met.get("pause_ratio", 0.0)),
            prosody_score=float(met.get("prosody_score", 0.0)),
            feedback=make_feedback(words),
        )
        db.add(segment)
        saved_segments.append(segment)
    return saved_segments


def process_voice(db: Session, file: UploadFile, user: User, category_id: int):
    ext = os.path.splitext(file.filename)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
        tmp.write(file.file.read())
        tmp_path = tmp.name

    object_name = f"voices/{uuid.uuid4()}"
    original_url = upload_file(tmp_path, object_name)

    # 1ë‹¨ê³„: Whisperë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œë§Œ (ë¬¸ì¥ë³„ë¡œ ë¶„ë¦¬ë¨)
    whisper_result = transcribe_audio(tmp_path, model_name="turbo", language="ko")
    full_text = whisper_result["text"]
    
    # 2ë‹¨ê³„: LLMìœ¼ë¡œ ë¬¸ë‹¨ë³„ ë¶„í• 
    try:
        llm_sections = classify_text_into_sections(full_text)
        # LLM ë¶„í•  ê²°ê³¼ë¥¼ Whisper segmentsì™€ ë§¤í•‘í•˜ì—¬ ì‹œê°„ ì •ë³´ ì¶”ê°€ (ë¬¸ë‹¨ ë‹¨ìœ„)
        mapped_paragraphs = map_llm_sections_to_whisper_segments(
            llm_sections, 
            whisper_result["segments"]
        )
        
        # ê° ë¬¸ë‹¨ ë²”ìœ„ ë‚´ì˜ Whisper segmentsë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë³€í™˜
        # ê° Whisper segmentëŠ” í•œ ë²ˆë§Œ ì‚¬ìš©ë˜ë„ë¡ ë³´ì¥
        used_segment_indices = set()  # ì´ë¯¸ ì‚¬ìš©ëœ Whisper segment ì¸ë±ìŠ¤
        sentence_segments = []
        
        if mapped_paragraphs:
            for paragraph in mapped_paragraphs:
                # ë¬¸ë‹¨ ì‹œê°„ ë²”ìœ„ ë‚´ì˜ Whisper segmentsë¥¼ ë¬¸ì¥ ë‹¨ìœ„ segmentë¡œ ë³€í™˜
                paragraph_sentences = map_sentences_to_whisper_segments(
                    paragraph["text"],
                    paragraph.get("part", ""),
                    paragraph["start"],
                    paragraph["end"],
                    whisper_result["segments"],
                    used_segment_indices  # ì‚¬ìš©ëœ ì¸ë±ìŠ¤ ì „ë‹¬
                )
                sentence_segments.extend(paragraph_sentences)
        
        # ë¬¸ì¥ ë‹¨ìœ„ segmentsê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì›ë³¸ Whisper segments ì‚¬ìš©
        if sentence_segments:
            # ì¶”ê°€ ì¤‘ë³µ ì œê±° (ì•ˆì „ì¥ì¹˜)
            final_segments = _remove_duplicate_segments(sentence_segments)
        else:
            # LLM ë¶„í•  ì‹¤íŒ¨ ì‹œ ì›ë³¸ Whisper segments ì‚¬ìš©
            print("LLM ë¶„í•  ì‹¤íŒ¨ ë˜ëŠ” ë¬¸ì¥ ë¶„í•  ì‹¤íŒ¨, ì›ë³¸ Whisper segments ì‚¬ìš©")
            final_segments = whisper_result["segments"]
    except Exception as e:
        # LLM ë¶„í•  ì‹¤íŒ¨ ì‹œ ì›ë³¸ Whisper segments ì‚¬ìš©
        print(f"LLM ë¶„í•  ì‹¤íŒ¨, ì›ë³¸ segments ì‚¬ìš©: {e}")
        final_segments = whisper_result["segments"]
    
    # 3ë‹¨ê³„: ë‚˜ë‰œ ë¬¸ì¥ë³„ë¡œ librosaë¡œ ë¶„ì„í•˜ì—¬ metrics ê³„ì‚°
    # ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
    y_audio, sr_audio = librosa.load(tmp_path, sr=16000)
    
    segments_with_metrics = []
    for seg in final_segments:
        metrics = analyze_segment_audio(
            tmp_path,
            seg["start"],
            seg["end"],
            seg["text"],
            y=y_audio,
            sr=sr_audio
        )
        
        # wordsì— metrics ì¶”ê°€ (feedback ê³„ì‚°ìš©)
        words_with_metrics = []
        for word in seg.get("words", []):
            word_metrics = analyze_segment_audio(
                tmp_path,
                word["start"],
                word["end"],
                y=y_audio,
                sr=sr_audio
            )
            words_with_metrics.append({
                "text": word["text"],
                "start": word["start"],
                "end": word["end"],
                "metrics": word_metrics
            })
        
        segments_with_metrics.append({
            "text": seg["text"],
            "part": seg.get("part"),
            "start": seg["start"],
            "end": seg["end"],
            "metrics": metrics,
            "words": words_with_metrics
        })
    
    segments_to_save = segments_with_metrics

    waveform_image = draw(tmp_path)

    # ğŸ”¹ DB ì €ì¥
    voice = Voice(
        user_id=user.id,
        category_id=category_id,
        filename=file.filename,
        content_type=file.content_type,
        original_url=original_url,
        duration_sec=whisper_result.get("duration")
    )
    db.add(voice)
    db.flush()

    saved_segments = save_segments_to_storage(tmp_path, voice.id, segments_to_save, db, voice, ext)
    db.commit()

    return {
        "voice_id": voice.id,
        "original_url": voice.original_url,
        "waveform_image": waveform_image,
        "segments": [
            {
                "id": seg.id,
                "order_no": seg.order_no,
                "text": seg.text,
                "part": seg.part,
                "start": seg.start_time,
                "end": seg.end_time,
                "segment_url": seg.segment_url,
                "feedback": seg.feedback,
                "metrics": {
                    "dB": seg.db,
                    "pitch_mean_hz": seg.pitch_mean_hz,
                    "rate_wpm": seg.rate_wpm,
                    "pause_ratio": seg.pause_ratio,
                    "prosody_score": seg.prosody_score,
                }
            } for seg in saved_segments
        ]
    }
